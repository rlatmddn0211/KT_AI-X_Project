{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"EQlim8VVT7C9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763990883017,"user_tz":-540,"elapsed":38231,"user":{"displayName":"ê¹€ìŠ¹ìš°","userId":"05314621828882951176"}},"outputId":"7edcefc0-1ffb-4dfd-cbff-b7e06e94d41c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8wcWY3jT6Ba"},"outputs":[],"source":["import os\n","os.chdir('drive/MyDrive/ì‹ë¬¼ì„ ë¶€íƒí•´/kjw')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YhXojZsnV8N0"},"outputs":[],"source":["import json\n","import cv2\n","import random\n","from google.colab.patches import cv2_imshow\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"umBcbh_Asji1"},"outputs":[],"source":["# ìŒ...ì´ê±´ ê·¸ëƒ¥ ì½”ë“œ ëŒë¦´ë•Œ ì¼ì •í•˜ê²Œ ë‚˜ì˜¬ë¼ê³  ì„¤ì •í•œ ê±°ì„.\n","# 1. íŒŒì´ì¬ ë‚´ì¥ random ì‹œë“œ ê³ ì •\n","random.seed(42)\n","\n","# 2. ë„˜íŒŒì´ ì‹œë“œ ê³ ì •\n","np.random.seed(42)\n","\n","# 3. TensorFlow ì‹œë“œ ê³ ì •\n","tf.random.set_seed(42)\n","\n","# 4. í™˜ê²½ ë³€ìˆ˜ (íŠ¹íˆ GPU ì—°ì‚°ì˜ ë¹„ê²°ì •ì„± ì œì–´)\n","os.environ[\"PYTHONHASHSEED\"] = \"42\"\n","os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"  # TF ì—°ì‚°ì„ ê²°ì •ì ìœ¼ë¡œ"]},{"cell_type":"markdown","metadata":{"id":"Hd9xpj1UZiuK"},"source":["# ì‹ë¬¼ì¢… ëª…ì‹œ(í•„ìˆ˜!!!!)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ztI_oBaGETPZ"},"outputs":[],"source":["plant_name = \"ìŠ¤íŒŒí‹°í•„ëŸ¼\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3SjE5QXZb3XS"},"outputs":[],"source":["\n","# (1) ë“œë¼ì´ë¸Œ â†’ Colabìœ¼ë¡œ ë³µì‚¬\n","!cp \"/content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/dataset(detection)/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection.zip\" \"/content/\"\n","\n","# (2) Colabì—ì„œ ì••ì¶• í•´ì œ\n","!unzip -q \"/content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection.zip\" -d \"/content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection\"\n","\n","# (3) ì••ì¶• íŒŒì¼ ì‚­ì œ (ìš©ëŸ‰ ì ˆì•½)\n","!rm \"/content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection.zip\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wcDmVamiVFCc"},"outputs":[],"source":["# # ???_dataset_classification\n","# # (1) ë“œë¼ì´ë¸Œ â†’ Colabìœ¼ë¡œ ë³µì‚¬\n","# !cp \"/content/drive/MyDrive/AI+Xá„€á…©á„€á…³á†¸/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/dataset(classification)/ì„ ì¸ì¥_dataset_classification.zip\" \"/content/\"\n","\n","# # (2) Colabì—ì„œ ì••ì¶• í•´ì œ\n","# !unzip -q \"/content/ì„ ì¸ì¥_dataset_classification.zip\" -d \"/content/ì„ ì¸ì¥_dataset_classification\"\n","\n","# # (3) ì••ì¶• íŒŒì¼ ì‚­ì œ (ìš©ëŸ‰ ì ˆì•½)\n","# !rm \"/content/ì„ ì¸ì¥_dataset_classification.zip\""]},{"cell_type":"markdown","metadata":{"id":"TCV8QFkMpHK6"},"source":["## 1. ê°ì²´ íƒì§€(YOLO11n) ëª¨ë¸ë§"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e7qPjm9frW8u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763991163519,"user_tz":-540,"elapsed":6015,"user":{"displayName":"ê¹€ìŠ¹ìš°","userId":"05314621828882951176"}},"outputId":"bc42948f-7ede-4832-9fc2-2a2c23c6ca8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.231-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n","Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n","Downloading ultralytics-8.3.231-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.231 ultralytics-thop-2.0.18\n"]}],"source":["# YOLOv11 ì„¤ì¹˜\n","!pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"8Fea3EecpGYh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763996803077,"user_tz":-540,"elapsed":5639554,"user":{"displayName":"ê¹€ìŠ¹ìš°","userId":"05314621828882951176"}},"outputId":"293981fa-2829-4354-e9bd-6df92993ecab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file âœ… \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","=== Stage 1: 960 / 15 epochs ===\n","Ultralytics 8.3.231 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=20, cls=0.5, compile=False, conf=None, copy_paste=0.15, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection/data.yaml, degrees=5.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.6, hsv_v=0.6, imgsz=960, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=stage1_960, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage1_960, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.3, seed=0, shear=2.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.08, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n","\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 16.4MB/s 0.0s\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n"," 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n"," 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n"," 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n","YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n","\n","Transferred 448/499 items from pretrained weights\n","Freezing layer 'model.23.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4198.2Â±943.6 MB/s, size: 1439.1 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection/train/labels... 5400 images, 0 backgrounds, 1 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5400/5400 1.6Kit/s 3.5s\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection/train/images/N50-A-2-07-B-1-H-230919-001013.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.7177      1.1315]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection/train/labels.cache\n","WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (7.8GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5399/5399 143.1it/s 37.7s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1663.3Â±1244.3 MB/s, size: 1564.3 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection/val/labels... 1800 images, 0 backgrounds, 2 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1800/1800 1.5Kit/s 1.2s\n","\u001b[34m\u001b[1mval: \u001b[0m/content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection/val/images/N50-A-2-07-B-1-H-230907-000165.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2171      1.1227      1.2963      1.7102]\n","\u001b[34m\u001b[1mval: \u001b[0m/content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection/val/images/N50-A-2-07-B-3-H-230902-000236.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.5009]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection/val/labels.cache\n","WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (2.6GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1798/1798 138.4it/s 13.0s\n","Plotting labels to /content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage1_960/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n","Image sizes 960 train, 960 val\n","Using 1 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage1_960\u001b[0m\n","Starting training for 15 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/15       2.5G      1.104      1.677      1.161         22        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.0it/s 2:49\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 6.5it/s 17.3s\n","                   all       1798       3596      0.909      0.887      0.939       0.67\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/15      2.51G      1.048     0.9492      1.107         44        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.4it/s 2:33\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.3it/s 11.0s\n","                   all       1798       3596      0.936      0.924      0.964      0.733\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/15      2.53G     0.9974     0.8023      1.078         28        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.5it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.2it/s 11.1s\n","                   all       1798       3596      0.945      0.908      0.969      0.741\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/15      2.54G     0.9478     0.7168      1.053         23        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.5it/s 2:31\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.3it/s 11.0s\n","                   all       1798       3596      0.961      0.963      0.978      0.748\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/15      2.56G     0.8896      0.646      1.022         19        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.4it/s 2:33\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.1it/s 11.2s\n","                   all       1798       3596      0.968      0.973      0.986      0.793\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/15      2.57G     0.8456      0.596      1.006         26        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.5it/s 2:32\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.1it/s 11.1s\n","                   all       1798       3596      0.975      0.981      0.988      0.838\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/15      2.59G     0.7996     0.5538     0.9872         35        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.5it/s 2:29\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.3it/s 10.9s\n","                   all       1798       3596      0.979      0.976       0.99      0.852\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/15       2.6G     0.7652     0.5156     0.9708         33        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.4it/s 2:32\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.2it/s 11.1s\n","                   all       1798       3596      0.983      0.979      0.991      0.885\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/15      2.62G     0.7387     0.4889     0.9618         35        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.4it/s 2:32\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.0it/s 11.3s\n","                   all       1798       3596      0.984      0.982      0.991      0.894\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/15      2.63G     0.7132     0.4614     0.9513         35        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.5it/s 2:31\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.3it/s 11.0s\n","                   all       1798       3596      0.979      0.989      0.992       0.91\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/15      2.65G     0.6868     0.4427     0.9417         36        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.5it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.3it/s 11.0s\n","                   all       1798       3596      0.987       0.99      0.992      0.908\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/15      2.66G     0.6657     0.4222     0.9361         35        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.5it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.2it/s 11.1s\n","                   all       1798       3596      0.992      0.992      0.993      0.912\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/15      2.68G      0.636     0.3979      0.922         36        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.5it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.3it/s 10.9s\n","                   all       1798       3596      0.991      0.993      0.993       0.93\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/15      2.69G     0.6131     0.3772     0.9158         40        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.5it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.0it/s 11.4s\n","                   all       1798       3596      0.993      0.994      0.993      0.939\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/15      2.71G     0.5902     0.3634      0.908         21        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 675/675 4.5it/s 2:30\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.2it/s 11.1s\n","                   all       1798       3596      0.993      0.994      0.993      0.943\n","\n","15 epochs completed in 0.683 hours.\n","Optimizer stripped from /content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage1_960/weights/last.pt, 5.5MB\n","Optimizer stripped from /content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage1_960/weights/best.pt, 5.5MB\n","\n","Validating /content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage1_960/weights/best.pt...\n","Ultralytics 8.3.231 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 113/113 10.1it/s 11.2s\n","                   all       1798       3596      0.993      0.995      0.993      0.943\n","Speed: 0.3ms preprocess, 2.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage1_960\u001b[0m\n","=== Stage 2: 1280 / +10 epochs (total 25) ===\n","Ultralytics 8.3.231 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=20, cls=0.5, compile=False, conf=None, copy_paste=0.15, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection/data.yaml, degrees=5.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.6, hsv_v=0.6, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15, mode=train, model=yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage1_960/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=stage2_1280_ft, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage2_1280_ft, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.3, seed=0, shear=2.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.08, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n"," 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n"," 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n"," 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n","YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n","\n","Transferred 499/499 items from pretrained weights\n","Freezing layer 'model.23.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3883.0Â±1144.0 MB/s, size: 1465.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection/train/labels.cache... 5400 images, 0 backgrounds, 1 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5400/5400 8.5Mit/s 0.0s\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection/train/images/N50-A-2-07-B-1-H-230919-001013.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.7177      1.1315]\n","WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (13.9GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5399/5399 120.8it/s 44.7s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2200.4Â±1814.2 MB/s, size: 1829.5 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection/val/labels.cache... 1800 images, 0 backgrounds, 2 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1800/1800 2.3Mit/s 0.0s\n","\u001b[34m\u001b[1mval: \u001b[0m/content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection/val/images/N50-A-2-07-B-1-H-230907-000165.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2171      1.1227      1.2963      1.7102]\n","\u001b[34m\u001b[1mval: \u001b[0m/content/ìŠ¤íŒŒí‹°í•„ëŸ¼_dataset_detection/val/images/N50-A-2-07-B-3-H-230902-000236.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.5009]\n","WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (4.6GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1798/1798 105.7it/s 17.0s\n","Plotting labels to /content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage2_1280_ft/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n","Image sizes 1280 train, 1280 val\n","Using 1 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage2_1280_ft\u001b[0m\n","Starting training for 10 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/10      2.56G     0.6659      0.423     0.9825          6       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1350/1350 4.6it/s 4:56\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 225/225 10.1it/s 22.2s\n","                   all       1798       3596      0.983      0.984      0.991      0.894\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/10      2.56G     0.7225     0.4775      1.008         16       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1350/1350 4.7it/s 4:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 225/225 13.2it/s 17.0s\n","                   all       1798       3596      0.983      0.982      0.993      0.877\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/10      2.56G     0.7266     0.4852      1.006         11       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1350/1350 4.9it/s 4:35\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 225/225 13.5it/s 16.7s\n","                   all       1798       3596       0.98       0.98      0.991      0.882\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/10      2.56G     0.7192     0.4797     0.9997          8       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1350/1350 4.9it/s 4:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 225/225 13.3it/s 16.9s\n","                   all       1798       3596      0.986      0.987      0.991      0.862\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/10      2.56G     0.6924     0.4519     0.9898          8       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1350/1350 4.8it/s 4:40\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 225/225 13.2it/s 17.0s\n","                   all       1798       3596      0.982       0.99       0.99      0.912\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/10      2.56G     0.6575     0.4229     0.9726         11       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1350/1350 4.8it/s 4:40\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 225/225 13.3it/s 16.9s\n","                   all       1798       3596       0.99       0.99      0.993      0.931\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/10      2.56G     0.6351     0.4009     0.9623         11       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1350/1350 4.9it/s 4:38\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 225/225 13.3it/s 16.9s\n","                   all       1798       3596      0.988      0.992      0.993      0.939\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/10      2.56G     0.6017     0.3719     0.9471         12       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1350/1350 4.8it/s 4:44\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 225/225 13.1it/s 17.1s\n","                   all       1798       3596      0.988      0.996      0.993      0.935\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/10      2.57G      0.574     0.3513     0.9353         15       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1350/1350 4.8it/s 4:40\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 225/225 13.1it/s 17.2s\n","                   all       1798       3596      0.988      0.996      0.993      0.949\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/10      2.57G     0.5511     0.3298     0.9272         14       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1350/1350 4.8it/s 4:39\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 225/225 13.3it/s 16.9s\n","                   all       1798       3596      0.994      0.993      0.993      0.951\n","\n","10 epochs completed in 0.831 hours.\n","Optimizer stripped from /content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage2_1280_ft/weights/last.pt, 5.6MB\n","Optimizer stripped from /content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage2_1280_ft/weights/best.pt, 5.6MB\n","\n","Validating /content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage2_1280_ft/weights/best.pt...\n","Ultralytics 8.3.231 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 225/225 14.4it/s 15.6s\n","                   all       1798       3596      0.994      0.993      0.993      0.951\n","Speed: 0.5ms preprocess, 4.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/á„‰á…µá†¨á„†á…®á†¯á„‹á…³á†¯ á„‡á…®á„á…¡á†¨á„’á…¢/kjw/yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage2_1280_ft\u001b[0m\n","\n","âœ… Done.\n","Stage1(best): yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage1_960/weights/best.pt\n","Stage2 runs : yolo_log/ìŠ¤íŒŒí‹°í•„ëŸ¼_yolo/detect/stage2_1280_ft\n","â†’ ìµœì¢… ë°°í¬ í›„ë³´ ê°€ì¤‘ì¹˜: stage2_1280_ft/weights/best.pt (ë˜ëŠ” last.pt)\n"]}],"source":["# -*- coding: utf-8 -*-\n","from ultralytics import YOLO\n","import os\n","\n","data_yaml  = f\"/content/{plant_name}_dataset_detection/data.yaml\"\n","project    = f\"yolo_log/{plant_name}_yolo/detect\"\n","\n","AUG = dict(\n","    hsv_h=0.015, hsv_s=0.60, hsv_v=0.60,\n","    degrees=5.0, translate=0.08, scale=0.30, shear=2.0,\n","    mosaic=1.0, mixup=0.15, copy_paste=0.15, close_mosaic=20,\n","    fliplr=0.5, flipud=0.0,\n",")\n","\n","# --- Stage 1: 960 / 15 epochs ---\n","print(\"=== Stage 1: 960 / 15 epochs ===\")\n","model = YOLO(\"yolo11n.pt\")\n","stage1_name = \"stage1_960\"\n","\n","results_stage1 = model.train(\n","    data=data_yaml,\n","    epochs=15,\n","    imgsz=960,\n","    batch=8,          # ì •ìˆ˜ë¡œ ì§€ì • (OOM ì‹œ 4 ë˜ëŠ” 2ë¡œ ë‚®ì¶”ê¸°)\n","    workers=1,\n","    cache=True,\n","    device=0,\n","    project=project,\n","    name=stage1_name,\n","    exist_ok=True,\n","    **AUG\n",")\n","\n","# --- Stage 2: 1280 / +10 epochs (total 25) ---\n","print(\"=== Stage 2: 1280 / +10 epochs (total 25) ===\")\n","best_stage1 = os.path.join(project, stage1_name, \"weights\", \"best.pt\")\n","assert os.path.exists(best_stage1), f\"Stage1 best.pt not found: {best_stage1}\"\n","\n","model1280 = YOLO(best_stage1)\n","stage2_name = \"stage2_1280_ft\"\n","\n","results_stage2 = model1280.train(\n","    data=data_yaml,\n","    epochs=10,\n","    imgsz=1280,\n","    batch=4,          # 1280ì€ ë©”ëª¨ë¦¬â†‘ â†’ ë” ë‚®ê²Œ (OOM ì‹œ 2 ë˜ëŠ” 1)\n","    workers=1,\n","    cache=True,\n","    device=0,\n","    project=project,\n","    name=stage2_name,\n","    exist_ok=True,\n","    **AUG\n",")\n","\n","print(f\"Stage1(best): {best_stage1}\")\n","print(f\"Stage2 runs : {os.path.join(project, stage2_name)}\")\n","print(\"â†’ ìµœì¢… ë°°í¬ í›„ë³´ ê°€ì¤‘ì¹˜: stage2_1280_ft/weights/best.pt (ë˜ëŠ” last.pt)\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mTllA18Kk-hA","colab":{"base_uri":"https://localhost:8080/","height":457},"executionInfo":{"status":"error","timestamp":1763704827020,"user_tz":-540,"elapsed":4285,"user":{"displayName":"ê¹€ìŠ¹ìš°","userId":"05314621828882951176"}},"outputId":"45c64d65-0c5d-49e5-979f-005435f6a1d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.229 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n","YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3320.1Â±760.1 MB/s, size: 1830.0 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/ë””íœë°”í‚¤ì•„_dataset_detection/val/labels.cache... 1800 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1800/1800 2.9Mit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 1% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/225 1.7s/it 1.8s<6:22\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3689709063.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mval_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_stage2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m metrics = val_model.val(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_yaml\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# ë™ì¼ data.yaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1280\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0;31m# í•™ìŠµ ë‹¨ê³„2ì™€ ë™ì¼ í•´ìƒë„\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mval\u001b[0;34m(self, validator, **kwargs)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0mvalidator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalidator\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0mvalidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/validator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplots\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_val_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_val_batch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/detect/val.py\u001b[0m in \u001b[0;36mplot_predictions\u001b[0;34m(self, batch, preds, ni, max_det)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# TODO: optimize this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_idx\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"conf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m  \u001b[0;31m# add batch index to predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mmax_det\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_det\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_det\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# -----------------------------\n","# ìµœì¢… ëª¨ë¸ ê²€ì¦(Validation)\n","#  - stage2(1280) best.pt ê¸°ì¤€\n","# -----------------------------\n","\n","best_stage2 = os.path.join(project, stage2_name, \"weights\", \"best.pt\")\n","assert os.path.exists(best_stage2), f\"Stage2 best.pt not found: {best_stage2}\"\n","\n","val_model = YOLO(best_stage2)\n","\n","metrics = val_model.val(\n","    data=data_yaml,          # ë™ì¼ data.yaml\n","    imgsz=1280,              # í•™ìŠµ ë‹¨ê³„2ì™€ ë™ì¼ í•´ìƒë„\n","    batch=8,                 # â˜… ì •ìˆ˜ë¡œ ì§€ì • (OOMë‚˜ë©´ 4 ë˜ëŠ” 2ë¡œ)\n","    device=0,\n","    project=project,\n","    name=\"val_stage2_1280\",  # ê²°ê³¼ ì €ì¥ í´ë”\n","    exist_ok=True,\n","    plots=True,              # PR/Confusion ë“± ê·¸ë˜í”„ ì €ì¥\n","    save_json=True           # COCO í¬ë§· ë©”íŠ¸ë¦­ JSON ì €ì¥\n",")\n","print(metrics)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gY7uJR48k-bS"},"outputs":[],"source":["# -----------------------------\n","# Test ì„¸íŠ¸ ì˜ˆì¸¡ (Prediction)\n","#  - stage2(1280) best.pt ê¸°ì¤€\n","#  - ì‘ì€ ìê¹Œì§€ ìµœëŒ€í•œ ë§ì´ íƒì§€í•˜ë„ë¡ ë¦¬ì½œ ì¤‘ì‹¬ íŒŒë¼ë¯¸í„°\n","# -----------------------------\n","\n","best_stage2 = os.path.join(project, stage2_name, \"weights\", \"best.pt\")\n","assert os.path.exists(best_stage2), f\"Stage2 best.pt not found: {best_stage2}\"\n","\n","test_model = YOLO(best_stage2)\n","\n","pred = test_model.predict(\n","    source=f\"/content/{plant_name}_dataset_detection/test/images\",  # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í´ë”\n","    data=data_yaml,\n","    save=True,                  # íƒì§€ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥\n","    imgsz=1280,                 # í•™ìŠµ(Stage2)ì™€ ë™ì¼ í•´ìƒë„\n","    conf=0.18,                  # â†“ ë‚®ì¶°ì„œ ì‘ì€ ì í›„ë³´ ë” ìˆ˜ì§‘(0.18~0.25 ë²”ìœ„ ì¡°ì • ê°€ëŠ¥)\n","    iou=0.70,                   # â†‘ ê²¹ì¹œ ì ë°•ìŠ¤ ìœ ì§€ (NMS ëœ ì§€ìš°ê²Œ)\n","    max_det=300,                # ì´ë¯¸ì§€ë‹¹ ë°•ìŠ¤ ìƒí•œ ëŠ˜ë¦¬ê¸°\n","    project=project,\n","    name=\"predict_stage2_1280\", # ê²°ê³¼ í´ë”ëª…\n","    exist_ok=True,\n","    save_txt=True,              # YOLO í¬ë§· ë¼ë²¨(txt) ì €ì¥\n","    save_conf=True,             # ê° ë°•ìŠ¤ confidence ì €ì¥\n","    verbose=True\n",")\n","\n","print(\"\\nâœ… Prediction ì™„ë£Œ\")\n","print(f\"ê²°ê³¼ í´ë”: {os.path.join(project, 'predict_stage2_1280')}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cg5I6fLakMtm"},"outputs":[],"source":["# -----------------------------\n","# Test ì„¸íŠ¸ í‰ê°€ (Evaluation)\n","#  - stage2(1280) best.pt ê¸°ì¤€\n","# -----------------------------\n","\n","# Stage2 best.pt ê²½ë¡œ ì§€ì •\n","best_stage2 = os.path.join(project, stage2_name, \"weights\", \"best.pt\")\n","assert os.path.exists(best_stage2), f\"Stage2 best.pt not found: {best_stage2}\"\n","\n","# ëª¨ë¸ ë¡œë“œ\n","yolo_best_model = YOLO(best_stage2)\n","\n","# í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€\n","metrics = yolo_best_model.val(\n","    data=data_yaml,             # ë™ì¼í•œ data.yaml ì‚¬ìš©\n","    split=\"test\",               # test ì„¸íŠ¸ í‰ê°€ ëª…ì‹œ\n","    imgsz=1280,                 # í•™ìŠµê³¼ ë™ì¼í•œ í•´ìƒë„\n","    batch=8,                    # Colab GPU ì—¬ìœ ì— ë”°ë¼ 4~8ë¡œ ì¡°ì •\n","    conf=0.25,                  # í‰ê°€ ê¸°ì¤€ confidence threshold\n","    iou=0.5,                    # mAP50 ê¸°ì¤€ (COCO mAP50-95ëŠ” ìë™ ê³„ì‚°)\n","    device=0,\n","    project=project,\n","    name=\"test_result_stage2_1280\",  # ê²°ê³¼ í´ë”ëª…\n","    exist_ok=True,\n","    plots=True,                 # PR curve, confusion matrix ë“± ì €ì¥\n","    save_json=True              # COCO í¬ë§· ê²°ê³¼ JSON ì €ì¥\n",")\n","\n","print(\"\\nâœ… Test ì„¸íŠ¸ í‰ê°€ ì™„ë£Œ\")\n","print(metrics)\n","print(f\"ê²°ê³¼ í´ë”: {os.path.join(project, 'test_result_stage2_1280')}\")\n"]},{"cell_type":"markdown","metadata":{"id":"YEfg4sRETWlU"},"source":["Epoch: í˜„ì¬ í•™ìŠµ ì¤‘ì¸ Epoch ë²ˆí˜¸\n","\n","GPU_mem: í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰\n","\n","box_loss / cls_loss / dfl_loss: í•™ìŠµ ì†ì‹¤(Loss) ê°’\n","\n"," box_loss: ë°”ìš´ë”© ë°•ìŠ¤ íšŒê·€ ì†ì‹¤\n","\n"," cls_loss: í´ë˜ìŠ¤ ë¶„ë¥˜ ì†ì‹¤ (ì´ë²ˆ ê²½ìš°ì—” leaf=0 í•˜ë‚˜ë¼ì„œ ì ì  ì‘ì•„ì§)\n","\n"," dfl_loss: ë¶„í¬ ì´ˆì  ì†ì‹¤ (YOLOì˜ anchor-free bounding box í’ˆì§ˆ)\n","\n","\n","Instances: ë°°ì¹˜ì— ë“¤ì–´ê°„ ê°ì²´(ë°”ìš´ë”©ë°•ìŠ¤) ê°œìˆ˜\n","\n","Size: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° (ex. 640Ã—640)"]},{"cell_type":"markdown","metadata":{"id":"iSxK7jWfTqWM"},"source":["P (Precision)\n","â†’ íƒì§€í•œ ê²ƒ ì¤‘ì—ì„œ ë§ì€ ë¹„ìœ¨ (ì •ë°€ë„)\n","\n","R (Recall)\n","â†’ ì‹¤ì œ ê°ì²´ ì¤‘ì—ì„œ íƒì§€í•œ ë¹„ìœ¨ (ì¬í˜„ìœ¨)\n","\n","mAP50 (mean Average Precision at IoU=0.5)\n","â†’ ê°€ì¥ ëŒ€í‘œì ì¸ ì •í™•ë„ ì§€í‘œ.\n","ê°’ì´ 1.0(100%)ì´ë©´ ê±°ì˜ ì™„ë²½í•œ íƒì§€ ì„±ëŠ¥.\n","\n","mAP50-95\n","â†’ IoU 0.5ë¶€í„° 0.95ê¹Œì§€ í‰ê· ë‚¸ AP. ë” ì—„ê²©í•œ ì§€í‘œ.\n","ë³´í†µ ì´ ê°’ì´ ëª¨ë¸ì˜ ì‹¤ì§ˆì ì¸ ì„±ëŠ¥ í‰ê°€ ê¸°ì¤€."]},{"cell_type":"markdown","metadata":{"id":"2ecG2TzmpKd_"},"source":["## 2. ë¶„ë¥˜ ëª¨ë¸ë§(MobileNetV3-Large)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ycM4PCQpOUs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762260859399,"user_tz":-540,"elapsed":4749,"user":{"displayName":"JW K","userId":"12247734576989807705"}},"outputId":"67b36266-d9cf-40c8-e1ed-702e027bed77"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 10799 images belonging to 3 classes.\n","Found 3600 images belonging to 3 classes.\n","Found 3600 images belonging to 3 classes.\n","Train classes: {'normal': 0, 'overwatered': 1, 'underwatered': 2}\n","Val   classes: {'normal': 0, 'overwatered': 1, 'underwatered': 2}\n","Test  classes: {'normal': 0, 'overwatered': 1, 'underwatered': 2}\n","class_weight: {np.int32(0): 0.9999074074074074, np.int32(1): 0.9999074074074074, np.int32(2): 1.0001852366398074}\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n","\u001b[1m12683000/12683000\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"]}],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, callbacks\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.mobilenet_v3 import preprocess_input # MobileNetV3ìš© ì…ë ¥ ì •ê·œí™” í•¨ìˆ˜\n","\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","# 1. ë°ì´í„°ì…‹ ê²½ë¡œ\n","data_dir = f\"/content/{plant_name}_dataset_classification\"   # train/ val/ test/ í•˜ìœ„ì— normal/ overwatered/ underwatered\n","\n","# 2. ë°ì´í„° ì „ì²˜ë¦¬ & ì¦ê°•\n","# MobileNetV3ëŠ” preprocess_input ì‚¬ìš©í•´ì•¼ ì •í™•ë„ê°€ ë†’ë‹¤ê³  í•¨.\n","train_datagen = ImageDataGenerator(\n","    preprocessing_function=preprocess_input, # ì •ê·œí™”\n","    rotation_range=15, # íšŒì „\n","    width_shift_range=0.1, # ì´ë™(width)\n","    height_shift_range=0.1, # ì´ë™(height)\n","    zoom_range=0.2, # í™•ëŒ€\n","    horizontal_flip=True # ì¢Œìš° ë°˜ì „\n",")\n","val_datagen  = ImageDataGenerator(preprocessing_function=preprocess_input) # ì¦ê°• ì—†ì´ ì •ê·œí™”ë§Œ ì§„í–‰\n","test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) # ì¦ê°• ì—†ì´ ì •ê·œí™”ë§Œ ì§„í–‰\n","\n","# 3. ì œë„ˆë ˆì´í„°(ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— í•œ ë²ˆì— ëª¨ë‘ ì˜¬ë¦¬ì§€ ì•Šê³ , ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì„œ ëª¨ë¸ì— ê³µê¸‰í•´ì£¼ëŠ” ê°ì²´)\n","BATCH = 32\n","IMG_SZ = (224, 224)\n","\n","\n","# í•™ìŠµ ë°ì´í„°ë¥¼ ë””ìŠ¤í¬ì—ì„œ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì‹¤ì‹œê°„ ë¡œë”© + ì¦ê°• ì ìš©\n","train_gen = train_datagen.flow_from_directory( # í´ë” êµ¬ì¡°ë¥¼ ìë™ìœ¼ë¡œ ë¼ë²¨ë§\n","    directory=f\"{data_dir}/train\",\n","    target_size=IMG_SZ,\n","    batch_size=BATCH,\n","    class_mode=\"categorical\", # ì›í•« ì¸ì½”ë”©ëœ ë²¡í„°ë¡œ ë¼ë²¨ì„ ë°˜í™˜\n","    shuffle=True\n",")\n","val_gen = val_datagen.flow_from_directory(\n","    directory=f\"{data_dir}/val\",\n","    target_size=IMG_SZ,\n","    batch_size=BATCH,\n","    class_mode=\"categorical\",\n","    shuffle=False # train ë°ì´í„°ë§Œ ì…”í”Œí•´ì•¼ í•¨.\n",")\n","test_gen = test_datagen.flow_from_directory(\n","    directory=f\"{data_dir}/test\",\n","    target_size=IMG_SZ,\n","    batch_size=BATCH,\n","    class_mode=\"categorical\",\n","    shuffle=False # train ë°ì´í„°ë§Œ ì…”í”Œí•´ì•¼ í•¨.\n",")\n","\n","\n","# 4. í´ë˜ìŠ¤ ë§¤í•‘ í™•ì¸\n","# ex.'normal':0, 'overwatered':1, 'underwatered':2 -> cf.ì´ë¯¸ì§€ íŒŒì¼ëª…ì˜ 0,1,2ë‘(ex. B-1-Hì˜ 1) ê´€ê³„ ì—†ìŒ\n","print(\"Train classes:\", train_gen.class_indices)\n","print(\"Val   classes:\", val_gen.class_indices)\n","print(\"Test  classes:\", test_gen.class_indices)\n","\n","NUM_CLASSES = train_gen.num_classes # í´ë˜ìŠ¤ ê°œìˆ˜\n","\n","\n","# 5. í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì •\n","y = train_gen.classes\n","unique, counts = np.unique(y, return_counts=True) # uniqueëŠ” ê° í´ë˜ìŠ¤, ê° í´ë˜ìŠ¤ ë¼ë²¨ë³„ë¡œ ëª‡ ì¥ ìˆëŠ”ì§€ ì§‘ê³„(count)\n","freq = {int(k): int(v) for k, v in zip(unique, counts)} # ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ìŒ(ex.{0:800, 1:150, 2:50})\n","total = len(y) # ì „ì²´ ë°ì´í„° ìˆ˜\n","class_weight = {c: (total / (NUM_CLASSES * freq[c])) for c in unique} # ì „ì²´ ìƒ˜í”Œìˆ˜ / (í´ë˜ìŠ¤ ê°œìˆ˜ x í•´ë‹¹ í´ë˜ìŠ¤ ìƒ˜í”Œ ìˆ˜) -> ë°ì´í„°ê°€ ì ì„ìˆ˜ë¡ weight ì»¤ì§\n","print(\"class_weight:\", class_weight)\n","\n","\n","# 6. MobileNetV3-Large ëª¨ë¸ ë¡œë“œ(ImageNetìœ¼ë¡œ ì‚¬ì „í•™ìŠµëœ íŠ¹ì§• ì¶”ì¶œê¸°(ë¶„ë¥˜ í—¤ë“œ ì œì™¸) ë¡œë“œ)\n","# ë¶„ë¥˜ í—¤ë“œ: ë”¥ëŸ¬ë‹ ëª¨ë¸ êµ¬ì¡°ì—ì„œ ë§ˆì§€ë§‰ ë‹¨ê³„(ì¶œë ¥ë¶€). ë”¥ëŸ¬ë‹ ëª¨ë¸: ëª¸í†µ(íŠ¹ì§• ì¶”ì¶œê¸°, backbone) + ë¨¸ë¦¬(ë¶„ë¥˜ê¸°, head) êµ¬ì¡°\n","cls_base_model = tf.keras.applications.MobileNetV3Large(\n","    input_shape=(IMG_SZ[0], IMG_SZ[1], 3), # 224Ã—224 í¬ê¸°ì˜ RGB ì´ë¯¸ì§€\n","    include_top=False, # ê¸°ì¡´ì˜ ë§ˆì§€ë§‰ ë¶„ë¥˜ ë ˆì´ì–´(softmax ë ˆì´ì–´)ë¥¼ ì œê±°í•˜ê³  ê°€ì ¸ì˜´. -> backbone(íŠ¹ì§• ì¶”ì¶œê¸°)ë§Œ ê°€ì ¸ì˜´\n","    weights=\"imagenet\" # ImageNet ë°ì´í„°ì…‹ìœ¼ë¡œ ë¯¸ë¦¬ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜´\n",")\n","cls_base_model.trainable = False # í•™ìŠµ ì¤‘ ì´ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ì§€ ì•Šê² ë‹¤ëŠ” ì˜ë¯¸(ì‚¬ì „ í•™ìŠµëœ íŠ¹ì§• ì¶”ì¶œê¸°(Backbone)ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©)\n","\n","\n","# 7. Backbone(MobileNetV3Large) ìœ„ì— ìƒˆë¡œìš´ ë¶„ë¥˜ê¸° í—¤ë“œ ë¶™ì´ê¸°\n","# GAP(GlobalAveragePooling2D)ìœ¼ë¡œ íŠ¹ì§• ë§µì„ ì••ì¶• -> íŠ¹ì§• ë§µì˜ ê³µê°„ ì°¨ì›(HÃ—W)ì„ í‰ê· ë‚´ì„œ 1D ë²¡í„°ë¡œ ë°”ê¿ˆ\n","# í´ë˜ìŠ¤ ìˆ˜ë§Œí¼ ì†Œí”„íŠ¸ë§¥ìŠ¤ Denseë¡œ ë¶„ë¥˜ê¸° í—¤ë“œ êµ¬ì„±.\n","x = layers.GlobalAveragePooling2D()(cls_base_model.output) # cls_base_model.output: MobileNetV3Largeì—ì„œ ë‚˜ì˜¨ íŠ¹ì§• ë§µ\n","x = layers.Dropout(0.4)(x)\n","output = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n","\n","# ìµœì¢… ëª¨ë¸ ê°ì²´ ìƒì„±\n","cls_model = models.Model(inputs=cls_base_model.input, outputs=output)\n","\n","\n","# 8. ì½œë°±\n","cb = [\n","    # ê²€ì¦ ì†ì‹¤ì´ 5 ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ì¤‘ë‹¨\n","    callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n","\n","    # val_loss ê¸°ì¤€ ë² ìŠ¤íŠ¸ ëª¨ë¸ë§Œ ì €ì¥\n","    callbacks.ModelCheckpoint(f\"mobilenetv3_log/val_log/{plant_name}_mobilenetv3_large_best.h5\", save_best_only=True, monitor=\"val_loss\"),\n","\n","    # ì •ì²´ë˜ë©´ í•™ìŠµë¥ ì„ ì ˆë°˜ìœ¼ë¡œ ë‚®ì¶° ë¯¸ì„¸ ì¡°ì •\n","    callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FxP2eKZxzF04","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762264556102,"user_tz":-540,"elapsed":3696700,"user":{"displayName":"JW K","userId":"12247734576989807705"}},"outputId":"44f23c15-66ac-415e-d768-8469e5a2b80e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 364ms/step - accuracy: 0.6921 - loss: 0.7397 - val_accuracy: 0.9556 - val_loss: 0.1376 - learning_rate: 0.0010\n","Epoch 2/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 358ms/step - accuracy: 0.9214 - loss: 0.2175 - val_accuracy: 0.9783 - val_loss: 0.0851 - learning_rate: 0.0010\n","Epoch 3/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 356ms/step - accuracy: 0.9467 - loss: 0.1598 - val_accuracy: 0.9814 - val_loss: 0.0696 - learning_rate: 0.0010\n","Epoch 4/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 356ms/step - accuracy: 0.9468 - loss: 0.1497 - val_accuracy: 0.9869 - val_loss: 0.0554 - learning_rate: 0.0010\n","Epoch 5/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 357ms/step - accuracy: 0.9534 - loss: 0.1368 - val_accuracy: 0.9850 - val_loss: 0.0561 - learning_rate: 0.0010\n","Epoch 6/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 357ms/step - accuracy: 0.9611 - loss: 0.1207 - val_accuracy: 0.9869 - val_loss: 0.0451 - learning_rate: 0.0010\n","Epoch 7/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 354ms/step - accuracy: 0.9620 - loss: 0.1172 - val_accuracy: 0.9842 - val_loss: 0.0464 - learning_rate: 0.0010\n","Epoch 8/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 358ms/step - accuracy: 0.9568 - loss: 0.1217 - val_accuracy: 0.9883 - val_loss: 0.0398 - learning_rate: 0.0010\n","Epoch 9/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 352ms/step - accuracy: 0.9567 - loss: 0.1214 - val_accuracy: 0.9872 - val_loss: 0.0400 - learning_rate: 0.0010\n","Epoch 10/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 356ms/step - accuracy: 0.9571 - loss: 0.1197 - val_accuracy: 0.9864 - val_loss: 0.0415 - learning_rate: 0.0010\n","Epoch 11/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.9616 - loss: 0.1113\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 352ms/step - accuracy: 0.9616 - loss: 0.1113 - val_accuracy: 0.9869 - val_loss: 0.0416 - learning_rate: 0.0010\n","Epoch 12/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 355ms/step - accuracy: 0.9583 - loss: 0.1184 - val_accuracy: 0.9911 - val_loss: 0.0331 - learning_rate: 5.0000e-04\n","Epoch 13/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 355ms/step - accuracy: 0.9638 - loss: 0.1007 - val_accuracy: 0.9906 - val_loss: 0.0313 - learning_rate: 5.0000e-04\n","Epoch 14/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 352ms/step - accuracy: 0.9655 - loss: 0.1055 - val_accuracy: 0.9903 - val_loss: 0.0331 - learning_rate: 5.0000e-04\n","Epoch 15/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 352ms/step - accuracy: 0.9654 - loss: 0.1072 - val_accuracy: 0.9906 - val_loss: 0.0322 - learning_rate: 5.0000e-04\n","Epoch 1/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 377ms/step - accuracy: 0.8468 - loss: 0.4934 - val_accuracy: 0.9933 - val_loss: 0.0253 - learning_rate: 1.0000e-05\n","Epoch 2/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 368ms/step - accuracy: 0.9287 - loss: 0.2104 - val_accuracy: 0.9936 - val_loss: 0.0215 - learning_rate: 1.0000e-05\n","Epoch 3/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 367ms/step - accuracy: 0.9479 - loss: 0.1556 - val_accuracy: 0.9950 - val_loss: 0.0160 - learning_rate: 1.0000e-05\n","Epoch 4/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 366ms/step - accuracy: 0.9614 - loss: 0.1209 - val_accuracy: 0.9964 - val_loss: 0.0120 - learning_rate: 1.0000e-05\n","Epoch 5/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 367ms/step - accuracy: 0.9687 - loss: 0.0846 - val_accuracy: 0.9972 - val_loss: 0.0091 - learning_rate: 1.0000e-05\n","Epoch 6/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 367ms/step - accuracy: 0.9767 - loss: 0.0732 - val_accuracy: 0.9981 - val_loss: 0.0065 - learning_rate: 1.0000e-05\n","Epoch 7/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 369ms/step - accuracy: 0.9803 - loss: 0.0561 - val_accuracy: 0.9986 - val_loss: 0.0047 - learning_rate: 1.0000e-05\n","Epoch 8/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 367ms/step - accuracy: 0.9852 - loss: 0.0418 - val_accuracy: 0.9986 - val_loss: 0.0038 - learning_rate: 1.0000e-05\n","Epoch 9/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 371ms/step - accuracy: 0.9865 - loss: 0.0387 - val_accuracy: 0.9992 - val_loss: 0.0029 - learning_rate: 1.0000e-05\n","Epoch 10/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 371ms/step - accuracy: 0.9873 - loss: 0.0381 - val_accuracy: 0.9992 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n","Epoch 11/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 374ms/step - accuracy: 0.9904 - loss: 0.0278 - val_accuracy: 0.9992 - val_loss: 0.0021 - learning_rate: 1.0000e-05\n","Epoch 12/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 370ms/step - accuracy: 0.9864 - loss: 0.0351 - val_accuracy: 0.9994 - val_loss: 0.0018 - learning_rate: 1.0000e-05\n","Epoch 13/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 365ms/step - accuracy: 0.9912 - loss: 0.0236 - val_accuracy: 0.9994 - val_loss: 0.0016 - learning_rate: 1.0000e-05\n","Epoch 14/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 369ms/step - accuracy: 0.9941 - loss: 0.0197 - val_accuracy: 0.9994 - val_loss: 0.0014 - learning_rate: 1.0000e-05\n","Epoch 15/15\n","\u001b[1m338/338\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 365ms/step - accuracy: 0.9918 - loss: 0.0237 - val_accuracy: 0.9994 - val_loss: 0.0011 - learning_rate: 1.0000e-05\n"]}],"source":["# 1st. ë¶„ë¥˜ê¸° í—¤ë“œë§Œ í•™ìŠµ\n","cls_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n","              loss=\"categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","history = cls_model.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=15,\n","    class_weight=class_weight,\n","    callbacks=cb\n",")\n","\n","\n","# 2nd. Fine-tuning (ìƒìœ„ ë¸”ë¡ í•™ìŠµ)\n","cls_base_model.trainable = True # Backboneí•™ìŠµì„ ìœ„í•´ Trueë¡œ ì „í™˜\n","n_unfreeze = 60  # ë§ˆì§€ë§‰ 60ê°œ ë ˆì´ì–´ë§Œ í•™ìŠµ\n","for layer in cls_base_model.layers[:-n_unfreeze]:\n","    layer.trainable = False # ë§ˆì§€ë§‰ n_unfreezeê°œë¥¼ ì œì™¸í•œ ì•ë¶€ë¶„ì€ False\n","# ì¦‰, ì €ìˆ˜ì¤€ feature (ì—£ì§€, ìƒ‰ìƒ, í…ìŠ¤ì²˜ ë“±) ì€ ê·¸ëŒ€ë¡œ ë‘ê³ ,\n","# ê³ ìˆ˜ì¤€ feature (ì ëª¨ì–‘, ë³‘ì¶©í•´ íŒ¨í„´ ë“±) ë¶€ë¶„ì„ ìƒˆ ë°ì´í„°ì…‹ì— ë§ê²Œ ë¯¸ì„¸ ì¡°ì •\n","\n","cls_model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n","              loss=\"categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","history_ft = cls_model.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=15,\n","    class_weight=class_weight,\n","    callbacks=cb\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"koXfckk9zIDG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762264561959,"user_tz":-540,"elapsed":5855,"user":{"displayName":"JW K","userId":"12247734576989807705"}},"outputId":"5787318d-d182-4d55-a089-fb57f2022811"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.9990 - loss: 0.0026\n","Test Accuracy: 0.9986, Test Loss: 0.0038\n"]}],"source":["# ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€\n","test_loss, test_acc = cls_model.evaluate(test_gen)\n","print(f\"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n","\n","# ì €ì¥\n","cls_model.save(f\"mobilenetv3_log/{plant_name}_mobilenetv3_large_best(final).keras\")"]},{"cell_type":"markdown","metadata":{"id":"d-vl2P524lUW"},"source":["## 3. ì¶”ë¡ (ì íƒì§€(YOLO) -> ì ì˜ì—­ ë¶„ë¦¬ -> ê±´ì¡°/ì¼ë°˜/ê³¼ìŠµ ë¶„ë¥˜)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7MkuQ_Ux5gJt","colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"status":"error","timestamp":1762254915055,"user_tz":-540,"elapsed":2304,"user":{"displayName":"JW K","userId":"12247734576989807705"}},"outputId":"7aaaa7dc-ce65-4ddc-debc-0d535f04c5ef"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2717477436.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_for_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLS_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclssification_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mcls_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mcls_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLASS_NAMES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m                 \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend_to_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[0mdeps_control_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNullContextmanager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeps_control_manager\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdeps_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m     \u001b[0mcurrent_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0mdefault_use_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    514\u001b[0m         ]\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m       \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_control_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;31m# Ensure all ops which must run do run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os, glob, csv, random\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","import pandas as pd\n","from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n","from ultralytics import YOLO\n","\n","# ê²½ë¡œ/ì„¤ì •\n","DET_WEIGHTS = f\"yolo_log/{plant_name}_yolo/detect/train/weights/best.pt\"   # YOLO ì íƒì§€ ëª¨ë¸\n","CLS_WEIGHTS = f\"mobilenetv3_log/{plant_name}_mobilenetv3_large_best(final).h5\"       # MobileNetV3-Large ë¶„ë¥˜ ëª¨ë¸\n","SOURCE = f\"/content/{plant_name}_dataset_detection/test/images\"       # ì¶”ë¡ í•  ì´ë¯¸ì§€ë“¤\n","\n","OUT_DIR = f\"yolo_log/{plant_name}_yolo/detect/test_results/{plant_name}_test_result_outputs\" # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ í´ë”\n","DRAW_DIR = os.path.join(OUT_DIR, \"draws\") # ì‹œê°í™”í•œ ì´ë¯¸ì§€(ë°”ìš´ë”© ë°•ìŠ¤ í¬í•¨)\n","CROP_DIR = os.path.join(OUT_DIR, \"crops\") # íƒì§€ëœ ì ë¶€ë¶„ë§Œ ì˜ë¼ë‚¸ ì´ë¯¸ì§€\n","os.makedirs(DRAW_DIR, exist_ok=True) # í´ë”ê°€ ì´ë¯¸ ìˆìœ¼ë©´ ì—ëŸ¬ë¥¼ ë‚´ì§€ ì•Šê³  ë„˜ì–´ê°\n","os.makedirs(CROP_DIR, exist_ok=True)\n","\n","YOLO_CONF = 0.5\n","YOLO_IOU  = 0.45\n","IMG_SIZE  = 640\n","CLS_SIZE  = (224, 224)\n","\n","CLASS_NAMES = [\"normal\", \"overwatered\", \"underwatered\"] # ì•ŒíŒŒë²³ ìˆœ(ë””ë ‰í„°ë¦¬ì— ì´ë ‡ê²Œ ì •ë ¬ë˜ì–´ ìˆìŒ)\n","\n","# ëª¨ë¸ ë¡œë“œ\n","detection_model = YOLO(DET_WEIGHTS)\n","clssification_model = tf.keras.models.load_model(CLS_WEIGHTS, compile=False)\n","\n","# ìœ í‹¸ í•¨ìˆ˜\n","def list_images(path):\n","    if os.path.isdir(path):\n","        imgs = glob.glob(os.path.join(path, \"*.jpg\"))\n","        return sorted(imgs)\n","    return [path]\n","\n","def preprocess_for_cls(bgr_img, size=(224,224)):\n","    rgb = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n","    rgb = cv2.resize(rgb, size, interpolation=cv2.INTER_AREA)\n","    x = preprocess_input(rgb.astype(np.float32))\n","    return np.expand_dims(x, axis=0)\n","\n","def clip_box(x1, y1, x2, y2, W, H):\n","    x1 = max(0, min(int(x1), W-1))\n","    y1 = max(0, min(int(y1), H-1))\n","    x2 = max(0, min(int(x2), W-1))\n","    y2 = max(0, min(int(y2), H-1))\n","    return x1, y1, x2, y2\n","\n","def get_true_label_from_filename(img_name):\n","    \"\"\"\n","    íŒŒì¼ëª… íŒ¨í„´ì—ì„œ GT í´ë˜ìŠ¤ ì¶”ì¶œ\n","    ê·œì¹™:\n","      'B-1-?' ë˜ëŠ” 'L-1-?' â†’ underwatered\n","      'B-2-?' ë˜ëŠ” 'L-2-?' â†’ normal\n","      'B-3-?' ë˜ëŠ” 'L-3-?' â†’ overwatered\n","    \"\"\"\n","    tokens = img_name.split(\"-\")\n","    for i in range(1, len(tokens) - 1):\n","        if tokens[i] in {\"1\",\"2\",\"3\"} and tokens[i-1].isalpha() and tokens[i+1].isalpha():\n","            return {\"1\":\"underwatered\", \"2\":\"normal\", \"3\":\"overwatered\"}[tokens[i]]\n","    raise ValueError(f\"GT í´ë˜ìŠ¤ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ: {img_name}\")\n","\n","# ì…ë ¥ ì´ë¯¸ì§€ ì¤€ë¹„\n","image_list = list_images(SOURCE)\n","assert len(image_list) > 0, f\"No images found in {SOURCE}\"\n","\n","# ì¶”ë¡  ë£¨í”„\n","csv_path = os.path.join(OUT_DIR, \"test_result_summary.csv\")\n","with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as csv_f:\n","    csv_w = csv.writer(csv_f)\n","    csv_w.writerow([\"image\",\"leaf_idx\",\"x1\",\"y1\",\"x2\",\"y2\",\"det_conf\",\"pred_class\",\"pred_prob\",\"true_class\",\"correct\"])\n","\n","    for img_path in image_list:\n","        img_name = os.path.basename(img_path)\n","        draw = cv2.imread(img_path)\n","        if draw is None:\n","            print(f\"[WARN] Cannot read image: {img_path}\")\n","            continue\n","        H, W = draw.shape[:2]\n","\n","        true_label = get_true_label_from_filename(img_name)\n","\n","        # YOLO íƒì§€\n","        results = detection_model.predict(source=img_path, imgsz=IMG_SIZE,\n","                                    conf=YOLO_CONF, iou=YOLO_IOU, verbose=False)\n","        r = results[0]; boxes = r.boxes\n","\n","        if boxes is None or len(boxes) == 0:\n","            cv2.imwrite(os.path.join(DRAW_DIR, img_name), draw)\n","            print(f\"[INFO] No leaves detected: {img_name}\")\n","            continue\n","\n","        # ë°•ìŠ¤ë³„ ë¶„ë¥˜\n","        for i, b in enumerate(boxes):\n","            x1, y1, x2, y2 = b.xyxy[0].tolist()\n","            conf = float(b.conf[0])\n","            x1, y1, x2, y2 = clip_box(x1, y1, x2, y2, W, H)\n","\n","            leaf = draw[y1:y2, x1:x2].copy()\n","            if leaf.size == 0: continue\n","\n","            x = preprocess_for_cls(leaf, CLS_SIZE)\n","            probs = clssification_model.predict(x, verbose=0)[0]\n","            cls_id = int(np.argmax(probs))\n","            cls_name = CLASS_NAMES[cls_id]\n","            cls_prob = float(probs[cls_id])\n","\n","            correct = int(cls_name == true_label)\n","\n","            # ì‹œê°í™”\n","            label = f\"{cls_name} {cls_prob:.2f} | det {conf:.2f}\"\n","            cv2.rectangle(draw, (x1, y1), (x2, y2), (0,200,0), 2)\n","            cv2.rectangle(draw, (x1, y1-22), (x1 + max(80, 8*len(label)), y1), (0,200,0), -1)\n","            cv2.putText(draw, label, (x1+4, y1-6), cv2.FONT_HERSHEY_SIMPLEX,\n","                        0.5, (0,0,0), 1, cv2.LINE_AA)\n","\n","            cv2.imwrite(os.path.join(CROP_DIR, f\"{os.path.splitext(img_name)[0]}_leaf{i}_{cls_name}.jpg\"), leaf)\n","            csv_w.writerow([img_name,i,x1,y1,x2,y2,f\"{conf:.4f}\",cls_name,f\"{cls_prob:.4f}\",true_label,correct])\n","\n","        cv2.imwrite(os.path.join(DRAW_DIR, img_name), draw)\n","        #print(f\"[DONE] {img_name} â†’ {os.path.join(DRAW_DIR, img_name)}\")\n","\n","# ì •í™•ë„ ê³„ì‚°\n","df = pd.read_csv(csv_path)\n","acc = df[\"correct\"].mean() if len(df) else 0.0\n","print(f\"ìµœì¢… ì •í™•ë„: {acc:.4f} (ì´ ìƒ˜í”Œ={len(df)})\")\n","print(f\"ê²°ê³¼ CSV: {csv_path}\")\n","print(f\"ì‹œê°í™” ì´ë¯¸ì§€: {DRAW_DIR}\")\n","print(f\"crop ì´ë¯¸ì§€: {CROP_DIR}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"liM_Cd2-YtYb"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}